import torch
import torch.nn as nn
import torch.utils.data as Data
import os
import numpy as np
from collections import Counter
import random
from model import CNN, ResNet, ResNet1, CNN_clip, ResNet_clip
from util import AverageMeter, accuracy, eval_metrics, draw_scatter
import clip
import torch
from sklearn.metrics import classification_report
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Random seed
RANDOM_SEED = 100
torch.manual_seed(RANDOM_SEED)
torch.cuda.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)
torch.backends.cudnn.deterministic = True

# Device
device = "cuda" if torch.cuda.is_available() else "cpu"
os.environ['CUDA_VISIBLE_DEVICES'] = '1'


# Load data
train_x = torch.from_numpy(np.load('./Datasets/x_train.npy')).float()
train_y = torch.from_numpy(np.load('./Datasets/y_train.npy')).long()
test_x = torch.from_numpy(np.load('./Datasets/x_test.npy')).float()
test_y = torch.from_numpy(np.load('./Datasets/y_test.npy')).long()

train_x = torch.unsqueeze(train_x, 1)
test_x = torch.unsqueeze(test_x, 1)
num_classes = len(Counter(train_y.tolist()))


classnames = ['lying', 'sitting','standing','walking', 'running','cycling','Nordic_walking','ascending_stairs','descending_stairs',
              'vacuum_cleaning','ironing','rope_jumping']

activityID = ['lying', 'sitting','standing','walking', 'running','cycling','Nordic walking','ascending stairs','descending stairs',
              'vacuum cleaning','ironing','rope jumping']
prompt = 'The human is '
text = []
for word in activityID:
    text.append(prompt + word)

# Load CLIP model
model, preprocess = clip.load("ViT-L/14", device=device)


# Text features of CLIP
text_tokenize = clip.tokenize(text).to(device)
text_features = model.encode_text(text_tokenize)
text_features = text_features.detach().float()

test_dataset = Data.TensorDataset(test_x, test_y)
test_loader = Data.DataLoader(dataset=test_dataset, batch_size=256, shuffle=False)

# Load pre-trained model
# Model definition
model = ResNet_clip(input_channel=1, num_classes=num_classes).to(device)

alpha = 0.2
print(alpha, ":")
checkpoint = './experiments_ResNet/experiments_imutextimg'+str(alpha)+'/best.pth.tar'

# Load model
# checkpoint = 'experiments_ResNet/experiments_imutextimg0.3/best.pth.tar'
if torch.cuda.is_available():
    checkpoint = torch.load(checkpoint)
model.load_state_dict(checkpoint['state_dict'])


# Test evaluate
top1_eval = AverageMeter()
top5_eval = AverageMeter()
f1_macro_eval = AverageMeter()
f1_micro_eval = AverageMeter()
model.eval()
GT = []
Pred_imutext = []
feature_list_imutext = []
for i, (val_batch, labels_batch) in enumerate(test_loader):
    val_batch, labels_batch = val_batch.cuda(), labels_batch.cuda()
            
    output_batch, imu_features = model(val_batch)
    
    feature_list_imutext = feature_list_imutext + imu_features.detach().cpu().tolist()
    
    
    score = imu_features @ text_features.t()
    similarity = (100.0 * imu_features @ text_features.t()).softmax(dim=-1)
    

    acc1, acc5, f1_ma, f1_mi = eval_metrics(similarity, labels_batch, topk=(1, 5))  # output:[32,100], target:[32]
    top1_eval.update(acc1[0], val_batch.size(0))
    top5_eval.update(acc5[0], val_batch.size(0)) 
    f1_macro_eval.update(f1_ma, val_batch.size(0)) 
    f1_micro_eval.update(f1_mi, val_batch.size(0)) 
    
    GT = GT + labels_batch.tolist()
    pred = np.argmax(similarity.detach().cpu().numpy(), axis=1)
    Pred_imutext = Pred_imutext + pred.tolist()
print(' * Acc@1 {top1_eval.avg:.3f} Acc@5 {top5_eval.avg:.3f} F1@macro {f1_macro_eval.avg:.3f} F1@micro {f1_micro_eval.avg:.3f}'.format(top1_eval=top1_eval, top5_eval=top5_eval, f1_macro_eval=f1_macro_eval, f1_micro_eval=f1_micro_eval))



# Load IMU only model
model = ResNet1(input_channel=1, num_classes=num_classes).to(device)
checkpoint = 'experiments_imuonly_new/best.pth.tar'
if torch.cuda.is_available():
    checkpoint = torch.load(checkpoint)
model.load_state_dict(checkpoint['state_dict'])

# Test evaluate
top1_eval = AverageMeter()
top5_eval = AverageMeter()
f1_macro_eval = AverageMeter()
f1_micro_eval = AverageMeter()
model.eval()
Pred_imu = []
feature_list_imu = []

for i, (val_batch, labels_batch) in enumerate(test_loader):
    val_batch, labels_batch = val_batch.cuda(), labels_batch.cuda()
            
    output_batch, features  = model(val_batch)

    feature_list_imu = feature_list_imu + features.detach().cpu().tolist()

    acc1, acc5, f1_ma, f1_mi = eval_metrics(output_batch, labels_batch, topk=(1, 5))  # output:[32,100], target:[32]
    top1_eval.update(acc1[0], val_batch.size(0))
    top5_eval.update(acc5[0], val_batch.size(0)) 
    f1_macro_eval.update(f1_ma, val_batch.size(0)) 
    f1_micro_eval.update(f1_mi, val_batch.size(0)) 
    
    _, output_batch = torch.max(output_batch.data, 1)
    Pred_imu = Pred_imu + output_batch.tolist()
print(' * Acc@1 {top1_eval.avg:.3f} Acc@5 {top5_eval.avg:.3f} F1@macro {f1_macro_eval.avg:.3f} F1@micro {f1_micro_eval.avg:.3f}'.format(top1_eval=top1_eval, top5_eval=top5_eval, f1_macro_eval=f1_macro_eval, f1_micro_eval=f1_micro_eval))



feature_tsne_np_imu = np.array(feature_list_imu)
feature_tsne_np_imutext = np.array(feature_list_imutext)
labels = np.array(GT)
# t-sne feature visualization
# imu+text feature visualize
tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)
low_dim_embs = tsne.fit_transform(feature_tsne_np_imutext)
draw_scatter(low_dim_embs, labels, 'title')
# plt.rcParams['figure.figsize'] = 20, 20
# plt.scatter(low_dim_embs[:, 0], low_dim_embs[:, 1], c=labels)
# plt.legend()

# imu feature visualize
tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)
low_dim_embs = tsne.fit_transform(feature_tsne_np_imu)
draw_scatter(low_dim_embs, labels, 'title')
# plt.rcParams['figure.figsize'] = 20, 20
# plt.scatter(low_dim_embs[:, 0], low_dim_embs[:, 1], c=labels)
# plt.legend()


# Per-class metrics
t_imu = classification_report(GT, Pred_imu)
print("imu-only:",t_imu)

t_imutxt = classification_report(GT, Pred_imutext)
print("imu+text:",t_imutxt)


# # correct is 1, wrong is 0
# correct_cls_imu = np.zeros((len(Pred_imu),1))
# correct_cls_imutext = np.zeros((len(Pred_imu),1))
# n_1,n_2=0,0
# for idx in range(len(Pred_imu)):
#     if Pred_imu[idx] == GT_1[idx]:
#         correct_cls_imu[idx] = 1
#         n_1 += 1
#     if Pred_imutext[idx] == GT_1[idx]:
#         correct_cls_imutext[idx] = 1
#         n_2 += 1
# print(n_1/len(Pred_imu),n_2/len(Pred_imu))        


# wrong_idx_imu = []
# wrong_idx_imutext = []
# for idx in range(len(Pred_imu)):
#     if Pred_imu[idx] != GT_1[idx]:
#         wrong_idx_imu.append([idx,GT_1[idx]])
#     if Pred_imutext[idx] != GT_1[idx]:
#         wrong_idx_imutext.append([idx,GT_1[idx]])
# wrong_idx_imu = np.array(wrong_idx_imu)
# wrong_idx_imutext = np.array(wrong_idx_imutext)

# from collections import Counter
# c_imu = Counter(wrong_idx_imu[:,1])
# c_imutext = Counter(wrong_idx_imutext[:,1])

# Wrong case large difference:
# class: 5   imu: 94   imutext: 7
# class: 7   imu: 102  imutext: 58
# class: 8   imu: 80   imutext: 47
# class: 10  imu: 194  imutext: 156

# class: 11  imu: 45   imutext: 108
